{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dsn36PRClv6n"
   },
   "source": [
    "# Estimating Regression Coefficients Using Maximum Likelihood for Logistic Regression\n",
    "\n",
    "## Theory\n",
    "\n",
    "In logistic regression, we use the logistic function to model a binary outcome. The logistic function is defined as:\n",
    "\n",
    "$$p(X) = \\frac{1}{1 + e^{-(b_0 + b_1X)}}$$\n",
    "\n",
    "where $p(X)$ represents the probability of the positive class (usually denoted as 1) given the input $X$. The logistic function maps the input values to a probability between 0 and 1.\n",
    "\n",
    "The coefficients $b_0$ and $b_1$ in the logistic function determine the shape of the sigmoid curve:\n",
    "- $b_0$ is the intercept term, which shifts the curve horizontally.\n",
    "- $b_1$ is the slope term, which determines the steepness of the curve.\n",
    "\n",
    "The likelihood function for a series of independent Bernoulli trials is:\n",
    "\n",
    "$$L(b_0, b_1) = \\prod_{i=1}^{n} p(X_i)^{Y_i}(1 - p(X_i))^{1 - Y_i}$$\n",
    "\n",
    "where $Y_i$ is the observed class label (0 or 1) for the $i$-th data point, and $p(X_i)$ is the predicted probability of the positive class for the $i$-th data point.\n",
    "\n",
    "The log-likelihood function is obtained by taking the logarithm of the likelihood function:\n",
    "\n",
    "$$\\ell(b_0, b_1) = \\sum_{i=1}^{n} [Y_i \\log(p(X_i)) + (1 - Y_i) \\log(1 - p(X_i))]$$\n",
    "\n",
    "The log-likelihood function is often used instead of the likelihood function because it simplifies the calculations and avoids numerical instability when dealing with small probabilities.\n",
    "\n",
    "To find the optimal values of $b_0$ and $b_1$ that maximize the log-likelihood, we can use numerical optimization methods such as gradient ascent. The gradients of the log-likelihood with respect to $b_0$ and $b_1$ are:\n",
    "\n",
    "$$\\frac{\\partial \\ell}{\\partial b_0} = \\sum_{i=1}^{n} (Y_i - p(X_i))$$\n",
    "$$\\frac{\\partial \\ell}{\\partial b_1} = \\sum_{i=1}^{n} (Y_i - p(X_i))X_i$$\n",
    "\n",
    "These gradients are used to update the coefficients iteratively until convergence or a specified number of steps is reached.\n",
    "\n",
    "## Python Implementation\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZ5W7JsRlwPf",
    "outputId": "40647f2b-aded-4b84-c8ca-a161e0ce501f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated coefficients (Maximum Likelihood): b0 = -1.7479414557849138, b1 = 0.4330671386606252\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def log_likelihood(X, Y, b0, b1):\n",
    "    logits = b0 + b1 * X\n",
    "    likelihood = np.sum(Y * np.log(logistic(logits)) + (1 - Y) * np.log(1 - logistic(logits)))\n",
    "    return likelihood\n",
    "\n",
    "# Gradient ascent settings\n",
    "steps = 100\n",
    "learning_rate = 0.01\n",
    "b0, b1 = 0.0, 0.0  # Initial guesses\n",
    "\n",
    "# Generate some binary data\n",
    "X_logistic = np.linspace(0, 10, num=100)\n",
    "Y_logistic = np.random.binomial(1, logistic(0.5 * X_logistic - 1))\n",
    "\n",
    "# Performing gradient ascent\n",
    "for step in range(steps):\n",
    "    logits = b0 + b1 * X_logistic\n",
    "    predictions = logistic(logits)\n",
    "    gradient_b0 = np.sum(Y_logistic - predictions)\n",
    "    gradient_b1 = np.sum((Y_logistic - predictions) * X_logistic)\n",
    "    b0 += learning_rate * gradient_b0\n",
    "    b1 += learning_rate * gradient_b1\n",
    "\n",
    "print(f\"Estimated coefficients (Maximum Likelihood): b0 = {b0}, b1 = {b1}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
