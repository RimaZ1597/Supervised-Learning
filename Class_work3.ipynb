{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380e0cdd-a9de-4113-8acf-097611eb0f2a",
   "metadata": {},
   "source": [
    "Convert categorical variables (Education Level, Job Level, Department) into numerical values using one-hot encoding or label encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4130f64e-ad38-4312-86b4-6fae441e9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb52972-4640-4f52-baf9-e62fe6c0aca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   experience  test_score(out of 10)  interview_score(out of 10)    salary($)  \\\n",
      "0         7.0                   10.0                         3.0  30165.13401   \n",
      "1        20.0                    3.0                         5.0  51861.98321   \n",
      "2        15.0                    3.0                         6.0  41332.07574   \n",
      "3        11.0                    4.0                         9.0  32120.10096   \n",
      "4         8.0                    7.0                         5.0  31400.55135   \n",
      "\n",
      "  education_level previous_company     skills       location  \n",
      "0          Master        Company H  Python, R    Los Angeles  \n",
      "1        Bachelor        Company E     SQL, R        Chicago  \n",
      "2          Master        Company A     R, SQL    Los Angeles  \n",
      "3          Master        Company B     R, SQL  San Francisco  \n",
      "4          Master        Company D     SQL, R    Los Angeles  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('NewDataset.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f0fef5a-f0c9-4f1b-a182-c9353ebee0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['experience', 'test_score(out of 10)', 'interview_score(out of 10)',\n",
      "       'salary($)', 'education_level', 'previous_company', 'skills',\n",
      "       'location'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9f11fd8-d447-49f4-9a01-2028117ad33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experience                    float64\n",
      "test_score(out of 10)         float64\n",
      "interview_score(out of 10)    float64\n",
      "salary($)                     float64\n",
      "education_level                object\n",
      "previous_company               object\n",
      "skills                         object\n",
      "location                       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8835887e-b066-48f3-a4a2-25d76041f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experience                    3\n",
      "test_score(out of 10)         3\n",
      "interview_score(out of 10)    1\n",
      "salary($)                     0\n",
      "education_level               0\n",
      "previous_company              0\n",
      "skills                        0\n",
      "location                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#df.isna().sum()\n",
    "# Step 2: Check for missing values\n",
    "missing_values = df.isna().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdb69a9e-2add-4939-ae62-ba5040d5960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after filtering:\n",
      "experience                    3\n",
      "test_score(out of 10)         0\n",
      "interview_score(out of 10)    0\n",
      "salary($)                     0\n",
      "education_level               0\n",
      "previous_company              0\n",
      "skills                        0\n",
      "location                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with the mean of the respective column\n",
    "df['test_score(out of 10)'].fillna(df['test_score(out of 10)'].mean(), inplace=True)\n",
    "df['interview_score(out of 10)'].fillna(df['interview_score(out of 10)'].mean(), inplace=True)\n",
    "\n",
    "# Verify that there are no more missing values\n",
    "missing_values_after = df.isna().sum()\n",
    "print(f\"Missing values after filtering:\\n{missing_values_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be977ef-1761-4eb6-90e6-0b1e5d3ba40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#creating instance of one hot encoder\n",
    "Onehotencoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db62e4-cf1d-419b-af87-dbf4de713266",
   "metadata": {},
   "source": [
    "class sklearn.preprocessing.OneHotEncoder(n_values='auto', categorical_features='Education Level', 'Job Level', 'Department', dtype=<type 'int'>, sparse=True, handle_unknown='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17cd1f5f-0f0b-4ed1-ae5f-296e621caca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoders for each categorical column\n",
    "le_education = LabelEncoder()\n",
    "le_company = LabelEncoder()\n",
    "le_location = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fa8dc82-3498-4cfc-a190-7624c2823c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LabelEncoder to each column\n",
    "df['education_level'] = le_education.fit_transform(df['education_level'])   \n",
    "df['previous_company'] = le_company.fit_transform(df['previous_company'])\n",
    "df['location'] = le_location.fit_transform(df['location'])                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1db39926-59c1-40d0-b9b5-225ab5d1b5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   experience  test_score(out of 10)  interview_score(out of 10)    salary($)  \\\n",
      "0         7.0                   10.0                         3.0  30165.13401   \n",
      "1        20.0                    3.0                         5.0  51861.98321   \n",
      "2        15.0                    3.0                         6.0  41332.07574   \n",
      "3        11.0                    4.0                         9.0  32120.10096   \n",
      "4         8.0                    7.0                         5.0  31400.55135   \n",
      "\n",
      "   education_level previous_company     skills       location  \n",
      "0                1        Company H  Python, R    Los Angeles  \n",
      "1                0        Company E     SQL, R        Chicago  \n",
      "2                1        Company A     R, SQL    Los Angeles  \n",
      "3                1        Company B     R, SQL  San Francisco  \n",
      "4                1        Company D     SQL, R    Los Angeles  \n"
     ]
    }
   ],
   "source": [
    "# Print the transformed DataFrame\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "34788bb9-dcd6-4080-b330-c5058fe054f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   experience  test_score(out of 10)  interview_score(out of 10)    salary($)  \\\n",
      "0   -0.484584               1.589838                   -0.859014  30165.13401   \n",
      "1    1.759575              -0.798383                   -0.184680  51861.98321   \n",
      "2    0.896437              -0.798383                    0.152488  41332.07574   \n",
      "3    0.205926              -0.457208                    1.163990  32120.10096   \n",
      "4   -0.311957               0.566315                   -0.184680  31400.55135   \n",
      "\n",
      "   education_level  previous_company  location  Python  R  SQL  \n",
      "0                1                 7         1       1  1    0  \n",
      "1                0                 4         0       0  1    1  \n",
      "2                1                 0         1       0  1    1  \n",
      "3                1                 1         3       0  1    1  \n",
      "4                1                 3         1       0  1    1  \n"
     ]
    }
   ],
   "source": [
    "# Apply OneHotEncoder to 'skills' column\n",
    "df = df.join(df['skills'].str.get_dummies(sep=', '))\n",
    "\n",
    "# Drop original 'skills' column as it's now one-hot encoded\n",
    "df.drop(columns=['skills'], inplace=True)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df[['experience', 'test_score(out of 10)', 'interview_score(out of 10)']] = scaler.fit_transform(\n",
    "    df[['experience', 'test_score(out of 10)', 'interview_score(out of 10)']]\n",
    ")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de9aa75-a3e3-41c4-98b5-015ead827571",
   "metadata": {},
   "source": [
    "Normalize or scale the numerical features (Years of Experience) if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dcdd87b4-13b8-4d91-be4b-aa3e023f1735",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 9) (40, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the features and the target variable\n",
    "X = df.drop(columns=['salary($)'])\n",
    "y = df['salary($)']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c552a7a0-9398-4b99-bf99-f2442313ad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experience                    3\n",
      "test_score(out of 10)         0\n",
      "interview_score(out of 10)    0\n",
      "salary($)                     0\n",
      "education_level               0\n",
      "previous_company              0\n",
      "location                      0\n",
      "Python                        0\n",
      "R                             0\n",
      "SQL                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "06820307-c394-4436-aee2-a6eeadc0b371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         experience  test_score(out of 10)  interview_score(out of 10)  \\\n",
      "count  1.970000e+02           2.000000e+02                2.000000e+02   \n",
      "mean  -8.791614e-17          -1.776357e-16               -1.776357e-17   \n",
      "std    1.002548e+00           1.002509e+00                1.002509e+00   \n",
      "min   -1.520350e+00          -1.480732e+00               -1.533349e+00   \n",
      "25%   -8.298395e-01          -7.983828e-01               -8.590142e-01   \n",
      "50%   -1.393289e-01          -1.160339e-01               -1.846796e-01   \n",
      "75%    8.964370e-01           9.074893e-01                8.268224e-01   \n",
      "max    1.759575e+00           1.589838e+00                1.501157e+00   \n",
      "\n",
      "          salary($)  education_level  previous_company    location  \\\n",
      "count    200.000000        200.00000        200.000000  200.000000   \n",
      "mean   33501.700093          0.92500          3.520000    1.505000   \n",
      "std    13794.035747          0.80786          2.283786    1.098183   \n",
      "min     3729.816420          0.00000          0.000000    0.000000   \n",
      "25%    23004.689272          0.00000          1.750000    1.000000   \n",
      "50%    33130.535795          1.00000          4.000000    1.000000   \n",
      "75%    44189.078817          2.00000          5.250000    2.250000   \n",
      "max    69084.437720          2.00000          7.000000    3.000000   \n",
      "\n",
      "           Python      R         SQL  \n",
      "count  200.000000  200.0  200.000000  \n",
      "mean     0.510000    1.0    0.745000  \n",
      "std      0.501154    0.0    0.436955  \n",
      "min      0.000000    1.0    0.000000  \n",
      "25%      0.000000    1.0    0.000000  \n",
      "50%      1.000000    1.0    1.000000  \n",
      "75%      1.000000    1.0    1.000000  \n",
      "max      1.000000    1.0    1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d99704e0-7427-47c6-9ea1-4b2bdeebf48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experience                    float64\n",
      "test_score(out of 10)         float64\n",
      "interview_score(out of 10)    float64\n",
      "salary($)                     float64\n",
      "education_level                 int64\n",
      "previous_company                int64\n",
      "location                        int64\n",
      "Python                          int64\n",
      "R                               int64\n",
      "SQL                             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d48adff0-3e68-4d91-b7ca-4eb9b9e47c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experience                    3\n",
      "test_score(out of 10)         0\n",
      "interview_score(out of 10)    0\n",
      "salary($)                     0\n",
      "education_level               0\n",
      "previous_company              0\n",
      "location                      0\n",
      "Python                        0\n",
      "R                             0\n",
      "SQL                           0\n",
      "dtype: int64\n",
      "experience                    3\n",
      "test_score(out of 10)         0\n",
      "interview_score(out of 10)    0\n",
      "salary($)                     0\n",
      "education_level               0\n",
      "previous_company              0\n",
      "location                      0\n",
      "Python                        0\n",
      "R                             0\n",
      "SQL                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(df.isnull().sum())\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fb22fc33-961f-4fc4-bf6a-31ba25c69757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d8937cb-a05a-474d-9aa9-dee0e8da2056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      200.000000\n",
      "mean     33501.700093\n",
      "std      13794.035747\n",
      "min       3729.816420\n",
      "25%      23004.689272\n",
      "50%      33130.535795\n",
      "75%      44189.078817\n",
      "max      69084.437720\n",
      "Name: salary($), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['salary($)'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c4266337-520d-4821-a6a8-5e2ed8f14ef0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model using the training data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    644\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    646\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 648\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    649\u001b[0m     X, y, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse, y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    650\u001b[0m )\n\u001b[1;32m    652\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[1;32m    653\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    654\u001b[0m )\n\u001b[1;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[1;32m    657\u001b[0m     X,\n\u001b[1;32m    658\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    662\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1109\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1110\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1111\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1112\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1113\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1114\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1115\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1116\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1117\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1118\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[1;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[1;32m    922\u001b[0m             array,\n\u001b[1;32m    923\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    924\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    925\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    926\u001b[0m         )\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432c516-6aeb-4396-8dd1-1f30611a8106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc6a220-ff17-42b8-8bd2-cfbcdf7d86e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
